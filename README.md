# Sign Language to Text/Speech Translation
This project focuses on real-time translation of word-level sign language into text and speech using CNN+LSTM and video processing. It aims to bridge the communication gap for individuals who rely on sign language.

## Key Features:
* Translation of 20 words and 3 words of ISL  from sign language to text and speech.  Video-based gesture recognition using a CNN+LSTM model.  
* Speech synthesis via the pyttsx3 TTS engine.
* Dataset: Indian Sign Word Level Dataset.
* Total Size: 4,292 videos (263-word signs across 20 categories).
* Project Subset: 2,400 videos (20 selected signs).
* Train-Test Split: 80% training (1,920 videos), 20% testing (480 videos).
* Video Input: 5-second recordings with 45 extracted frames
This system demonstrates an efficient and scalable approach to sign language recognition and translation, making communication more inclusive.
## Getting Started
DataSet Link : [https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset](https://zenodo.org/records/4010759)
### Download and Copy the Code inside a new Folder and open VS Code
Unzip "eyzip" file and run each commands
Processed videos for each words will be stored inside the same folder
## Screenshots of the WebApp
![Screenshot](output-1.jpg)
![Screenshot](output-2.jpg)
